{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet"
      ],
      "metadata": {
        "id": "M4-Z8B9mtLMP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1BZ0qpZs-vs"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import InceptionResNetV2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "\n",
        "number_of_classes = 7\n",
        "\n",
        "# Chemins des répertoires de données d'entraînement et de test\n",
        "train_data_dir = r\"/content/drive/MyDrive/Fil_rouge/Dataset/archive(3)/DATASET/train\"\n",
        "test_data_dir = r\"/content/drive/MyDrive/Fil_rouge/Dataset/archive(3)/DATASET/test\"\n",
        "\n",
        "# Prétraitement des données d'entraînement\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,          # Redimensionner les valeurs des pixels à [0, 1]\n",
        "    rotation_range=15,       # Rotation aléatoire des images de 15 degrés\n",
        "    width_shift_range=0.1,   # Décalage horizontal aléatoire jusqu'à 10%\n",
        "    height_shift_range=0.1,  # Décalage vertical aléatoire jusqu'à 10%\n",
        "    shear_range=0.1,         # Cisaillement aléatoire jusqu'à 10%\n",
        "    zoom_range=0.1,          # Zoom aléatoire jusqu'à 10%\n",
        "    horizontal_flip=True,    # Flip horizontal aléatoire\n",
        "    fill_mode='nearest'      # Remplir les pixels vides avec la valeur du pixel le plus proche\n",
        ")\n",
        "\n",
        "# Prétraitement des données de test\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Redimensionner les valeurs des pixels à [0, 1]\n",
        "\n",
        "# Générateur de données d'entraînement\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,         # Répertoire contenant les images d'entraînement\n",
        "    target_size=(100, 100), # Redimensionner toutes les images à 100x100 pixels\n",
        "    batch_size=32,          # Traiter les images par lots de 32\n",
        "    class_mode='categorical'# Les étiquettes des classes sont codées de manière catégorielle\n",
        ")\n",
        "\n",
        "# Générateur de données de test\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,          # Répertoire contenant les images de test\n",
        "    target_size=(100, 100), # Redimensionner toutes les images à 100x100 pixels\n",
        "    batch_size=32,          # Traiter les images par lots de 32\n",
        "    class_mode='categorical', # Les étiquettes des classes sont codées de manière catégorielle\n",
        "    shuffle=False           # Ne pas mélanger les images lors de la génération de lots\n",
        ")\n",
        "\n",
        "# Chargement du modèle de base InceptionResNetV2 pré-entraîné\n",
        "base_model = InceptionResNetV2(include_top=False, input_shape=(100, 100, 3))\n",
        "\n",
        "# Construction du modèle séquentiel\n",
        "model = Sequential()\n",
        "model.add(base_model)                  # Ajouter le modèle de base\n",
        "model.add(GlobalAveragePooling2D())    # Appliquer un pool moyen global 2D\n",
        "model.add(Dropout(0.5))                # Appliquer un dropout de 50% pour régularisation\n",
        "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))  # Couche dense avec régularisation L2\n",
        "model.add(Dense(number_of_classes, activation='softmax'))  # Couche de sortie pour classification\n",
        "\n",
        "# Compilation du modèle\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Geler les couches du modèle de base sauf les 10 dernières\n",
        "for layer in base_model.layers[:-10]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Définition du scheduler d'apprentissage\n",
        "def lr_scheduler(epoch, lr):\n",
        "    return lr * 0.95\n",
        "\n",
        "# Callback pour ajuster le taux d'apprentissage\n",
        "lr_callback = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "# Entraînement du modèle\n",
        "history = model.fit(\n",
        "    train_generator,                  # Générateur de données d'entraînement\n",
        "    steps_per_epoch=len(train_generator),  # Nombre de pas par époque\n",
        "    epochs=40,                        # Nombre d'époques d'entraînement\n",
        "    validation_data=test_generator,    # Générateur de données de validation\n",
        "    validation_steps=len(test_generator), # Nombre de pas de validation\n",
        "    callbacks=[lr_callback]            # Utiliser le callback pour ajuster le taux d'apprentissage\n",
        ")\n",
        "\n",
        "# Tracer les courbes de précision et de perte\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Prédictions sur les données de test\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Générer la matrice de confusion\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices)\n",
        "cmd.plot(cmap=plt.cm.Blues)\n",
        "plt.show()\n"
      ]
    }
  ]
}